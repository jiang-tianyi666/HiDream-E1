# ğŸš€ NPU å¿«é€Ÿå¼€å§‹æŒ‡å—ï¼ˆ5åˆ†é’Ÿç‰ˆï¼‰

å¦‚æœä½ çš„åä¸ºæœåŠ¡å™¨**å·²ç»é…ç½®å¥½ CANN å’Œ torch_npu**ï¼ŒæŒ‰ç…§è¿™ä¸ªå¿«é€ŸæŒ‡å—æ“ä½œã€‚

è¯¦ç»†æŒ‡å—è§ï¼š[HUAWEI_NPU_SETUP_GUIDE.md](HUAWEI_NPU_SETUP_GUIDE.md)

---

## âš¡ è¶…å¿«é€Ÿéƒ¨ç½²ï¼ˆå‡è®¾ç¯å¢ƒå·²é…ç½®ï¼‰

```bash
# 1. ä¸Šä¼ ä»£ç åˆ°æœåŠ¡å™¨
scp -r /Users/jty/File/MLLM/HiDream-E1 user@server:/home/user/

# 2. SSH ç™»å½•æœåŠ¡å™¨
ssh user@server

# 3. è¿›å…¥é¡¹ç›®ç›®å½•
cd ~/HiDream-E1

# 4. æ¿€æ´»ç¯å¢ƒï¼ˆå¦‚æœä½¿ç”¨è™šæ‹Ÿç¯å¢ƒï¼‰
conda activate your_env  # æˆ– source venv/bin/activate

# 5. å®‰è£…ä¾èµ–
pip install -r requirements_npu.txt

# 6. ç™»å½• HuggingFace
huggingface-cli login

# 7. æµ‹è¯•ç¯å¢ƒ
python test_npu_setup.py

# 8. è¿è¡Œæ¨ç†
python inference_e1_1_npu.py
```

**å®Œæˆï¼** ç»“æœä¿å­˜åœ¨ `results/test_1_npu.jpg`

---

## ğŸ“ å¿…é¡»æ£€æŸ¥çš„äº‹é¡¹

### 1ï¸âƒ£ NPU å¯ç”¨æ€§
```bash
python -c "import torch; import torch_npu; print('NPU:', torch.npu.is_available())"
```
**å¿…é¡»è¾“å‡º**: `NPU: True`

### 2ï¸âƒ£ CANN ç¯å¢ƒå˜é‡
```bash
echo $ASCEND_TOOLKIT_HOME
```
**åº”è¯¥è¾“å‡º**: `/usr/local/Ascend/ascend-toolkit/latest` æˆ–ç±»ä¼¼è·¯å¾„

### 3ï¸âƒ£ NPU è®¾å¤‡çŠ¶æ€
```bash
npu-smi info
```
**åº”è¯¥çœ‹åˆ°**: NPU è®¾å¤‡åˆ—è¡¨å’ŒçŠ¶æ€

---

## ğŸ¯ æ ¸å¿ƒæ–‡ä»¶è¯´æ˜

| æ–‡ä»¶ | ç”¨é€” | ä½•æ—¶ä½¿ç”¨ |
|------|------|----------|
| **inference_e1_1_npu.py** | E1.1 æ¨ç†è„šæœ¬ | æ¨èï¼Œæ”¯æŒåŠ¨æ€åˆ†è¾¨ç‡ |
| **inference_npu.py** | E1-Full æ¨ç†è„šæœ¬ | éœ€è¦æŒ‡ä»¤ä¼˜åŒ–åŠŸèƒ½æ—¶ |
| **gradio_demo_npu.py** | Web äº¤äº’ç•Œé¢ | éœ€è¦å¯è§†åŒ–ç•Œé¢æ—¶ |
| **test_npu_setup.py** | ç¯å¢ƒæµ‹è¯• | é¦–æ¬¡éƒ¨ç½²æˆ–é‡åˆ°é—®é¢˜æ—¶ |
| **device_utils.py** | è®¾å¤‡ç®¡ç†å·¥å…· | è¢«å…¶ä»–è„šæœ¬è‡ªåŠ¨è°ƒç”¨ |
| **run_npu.sh** | ä¸€é”®å¯åŠ¨è„šæœ¬ | æ‡’äººæ¨¡å¼ ğŸ˜„ |

---

## ğŸ”§ ä¸‰ä¸ªå¸¸ç”¨å‘½ä»¤

### 1. æµ‹è¯•ç¯å¢ƒ
```bash
python test_npu_setup.py
```

### 2. è¿è¡Œæ¨ç†
```bash
python inference_e1_1_npu.py
```

### 3. å¯åŠ¨ Web ç•Œé¢
```bash
python gradio_demo_npu.py
# ç„¶åè®¿é—® http://server-ip:7860
```

---

## âš™ï¸ ç¯å¢ƒå˜é‡é€ŸæŸ¥

```bash
# åœ¨ ~/.bashrc ä¸­æ·»åŠ ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
export ASCEND_HOME=/usr/local/Ascend
export ASCEND_TOOLKIT_HOME=${ASCEND_HOME}/ascend-toolkit/latest
source ${ASCEND_TOOLKIT_HOME}/set_env.sh

# å¯é€‰ï¼šæŒ‡å®š NPU è®¾å¤‡
export NPU_VISIBLE_DEVICES=0

# å¯é€‰ï¼šHuggingFace ç¼“å­˜
export HF_HOME=/data/huggingface
```

**ä¿®æ”¹åè®°å¾—**:
```bash
source ~/.bashrc
```

---

## ğŸ› å¿«é€Ÿæ’é”™

### é—®é¢˜ï¼šNPU ä¸å¯ç”¨
```bash
# æ£€æŸ¥é©±åŠ¨
npu-smi info

# é‡æ–°åŠ è½½ç¯å¢ƒ
source ~/.bashrc
```

### é—®é¢˜ï¼štorch_npu å¯¼å…¥å¤±è´¥
```bash
# é‡æ–°å®‰è£…
pip uninstall torch_npu
pip install torch_npu

# æ£€æŸ¥ç‰ˆæœ¬åŒ¹é…
python -c "import torch; print(torch.__version__)"
```

### é—®é¢˜ï¼šå†…å­˜ä¸è¶³
```bash
# æ–¹æ³•1ï¼šå‡å°‘åˆ†è¾¨ç‡
# ç¼–è¾‘è„šæœ¬ï¼Œä¿®æ”¹ image_size=768 (ä»1024é™åˆ°768)

# æ–¹æ³•2ï¼šå‡å°‘æ­¥æ•°
# ä¿®æ”¹ steps=20 (ä»28é™åˆ°20)

# æ–¹æ³•3ï¼šå¯ç”¨ CPU offload
# åœ¨è„šæœ¬ä¸­æ·»åŠ : pipe.enable_model_cpu_offload()
```

### é—®é¢˜ï¼šæ¨¡å‹ä¸‹è½½æ…¢
```bash
# ä½¿ç”¨é•œåƒ
export HF_ENDPOINT=https://hf-mirror.com
```

---

## ğŸ“Š æ€§èƒ½è°ƒä¼˜é€ŸæŸ¥

### æå‡é€Ÿåº¦
```python
# ä¿®æ”¹ inference_e1_1_npu.py ç¬¬32è¡Œ
os.environ["DIFFUSERS_ATTENTION_TYPE"] = "sdpa"  # ä» "vanilla" æ”¹ä¸º "sdpa"

# å‡å°‘æ¨ç†æ­¥æ•°
steps=20  # ä» 28 æ”¹ä¸º 20
```

### èŠ‚çœå†…å­˜
```python
# é™ä½åˆ†è¾¨ç‡
image_size=768  # ä» 1024 æ”¹ä¸º 768

# ä½¿ç”¨ float16
# ä¼šè‡ªåŠ¨æ£€æµ‹ï¼Œå¦‚æœ bfloat16 ä¸æ”¯æŒä¼šé™çº§
```

---

## ğŸ“– å®Œæ•´æ–‡æ¡£ç´¢å¼•

| æ–‡æ¡£ | ç”¨é€” |
|------|------|
| **QUICK_START_NPU.md** (æœ¬æ–‡æ¡£) | 5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹ |
| **HUAWEI_NPU_SETUP_GUIDE.md** | å®Œæ•´éƒ¨ç½²æŒ‡å—ï¼ˆä»é›¶å¼€å§‹ï¼‰|
| **README_NPU.md** | ä½¿ç”¨è¯´æ˜å’Œæ³¨æ„äº‹é¡¹ |
| **NPU_MIGRATION_GUIDE.md** | æŠ€æœ¯è¿ç§»ç»†èŠ‚ |
| **FLASH_ATTENTION_SOLUTIONS.md** | Flash Attention é—®é¢˜è§£å†³ |
| **NPU_MODIFICATIONS_SUMMARY.md** | ä»£ç ä¿®æ”¹æ€»ç»“ |

---

## âœ… æœ€å°åŒ–éªŒè¯æµç¨‹

**åªéœ€ 3 ä¸ªå‘½ä»¤ç¡®è®¤ç¯å¢ƒ OKï¼š**

```bash
# 1. NPU å¯ç”¨
python -c "import torch,torch_npu; assert torch.npu.is_available()"

# 2. è®¾å¤‡ç®¡ç†å™¨æ­£å¸¸
python -c "from device_utils import DeviceManager; dm=DeviceManager(); print(dm)"

# 3. æµ‹è¯•å¼ é‡è¿ç®—
python -c "import torch; x=torch.randn(10,10).to('npu:0'); print('âœ“ OK')"
```

**å…¨éƒ¨é€šè¿‡ï¼Ÿç«‹å³è¿è¡Œæ¨ç†ï¼**

---

## ğŸ‰ æˆåŠŸæ ‡å¿—

è¿è¡Œæ¨ç†åï¼Œçœ‹åˆ°è¿™äº›è¯´æ˜æˆåŠŸï¼š

```
âœ“ Models loaded successfully!
  Device: npu:0
  Data type: torch.bfloat16
...
âœ“ Image editing completed successfully!
  Output saved to: results/test_1_npu.jpg
  Inference time: 14.32 seconds
```

---

éœ€è¦å¸®åŠ©ï¼Ÿ
- ğŸ“– æŸ¥çœ‹å®Œæ•´æŒ‡å—ï¼šHUAWEI_NPU_SETUP_GUIDE.md
- ğŸ” è¿è¡Œè¯Šæ–­ï¼š`python test_npu_setup.py`
- ğŸ’¬ æäº¤ Issue æˆ–å’¨è¯¢åä¸ºæŠ€æœ¯æ”¯æŒ
